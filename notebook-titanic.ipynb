{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/benotroussel/notebook-titanic?scriptVersionId=137834125\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<font size=\"3\"> \n    \n<b> Welcome to my notebook on the Titanic dataset. \n    \nAlthough I'm relatively new to Kaggle, I've tried to ensure the techniques applied here are valuable and interesting, providing my approach to this well-known challenge. The intention of sharing this notebook is not just to showcase my efforts, but also to invite constructive feedback from the Kaggle community. By opening my methods to scrutiny, I hope to refine my data science skills and improve upon future iterations. This notebook aims to serve as a stepping stone for fellow beginners, illustrating my process from data exploration to prediction. Nevertheless, I'm aware that there's always room for improvement. So, please feel free to suggest alternative strategies or areas for refinement. Your input is appreciated.\n\n<b> Enjoy exploring this notebook! \n\n</font>","metadata":{}},{"cell_type":"markdown","source":"# Titanic Dataset\n","metadata":{}},{"cell_type":"markdown","source":"## Dataset Description\n\n### Overview\n\nThe data has been split into two groups:\n- training set (`train.csv`)\n- test set (`test.csv`)\n\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers, gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n","metadata":{}},{"cell_type":"markdown","source":"\n### Data Dictionary\n\n| Variable  | Definition                              | Key                             |\n| --------- | -------------------------------------- | ------------------------------- |\n| `survival`  | Survival                               | 0 = No, 1 = Yes                 |\n| `pclass`    | Ticket class                           | 1 = 1st, 2 = 2nd, 3 = 3rd      |\n| `sex`       | Sex                                    |                                 |\n| `Age`       | Age in years                           |                                 |\n| `sibsp`     | # of siblings / spouses aboard the Titanic |                              |\n| `parch`     | # of parents / children aboard the Titanic |                              |\n| `ticket`    | Ticket number                          |                                 |\n| `fare`      | Passenger fare                         |                                 |\n| `cabin`     | Cabin number                           |                                 |\n| `embarked`  | Port of Embarkation                    | S = Southampton (UK), C = Cherbourg (France), Q = Queenstown (Ireland)  |\n\n\nEmbarkation ordered and in direction the USA.\n\n### Variable Notes\n- `pclass`: A proxy for socio-economic status (SES)\n  - 1st = Upper\n  - 2nd = Middle\n  - 3rd = Lower\n- `age`: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n- `sibsp`: The dataset defines family relations in this way...\n  - Sibling = brother, sister, stepbrother, stepsister\n  - Spouse = husband, wife (mistresses and fiancés were ignored)\n- `parch`: The dataset defines family relations in this way...\n  - Parent = mother, father\n  - Child = daughter, son, stepdaughter, stepson\n","metadata":{}},{"cell_type":"markdown","source":"\n### Some help for the EDA :\n\nhttps://www.kaggle.com/code/allohvk/titanic-missing-age-imputation-tutorial-advanced/notebook\n\nhttps://www.kaggle.com/code/allohvk/titanic-advanced-eda?scriptVersionId=77739368\n\nhttps://github.com/Kaggle/kaggle-api","metadata":{}},{"cell_type":"markdown","source":"## Imports and configuration","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n%config InlineBackend.figure_format = \"retina\"\n\n!kaggle config set -n competition -v titanic","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train = pd.read_csv(\"train.csv\")\ntitanic_test = pd.read_csv(\"test.csv\")\ncombined_dataset = titanic_train.append(titanic_test)\n\ntitanic_train.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When trying to visualize datas, make assumption with respect to the survivibility of passengers, use the titanic train dataset. We don't want to make some leakeage from the test to the traind dataset. Then, when post-processing techniques / filling missing values, you can applied your findings from the train dataset to the test dataset (`combined_dataset`).","metadata":{}},{"cell_type":"markdown","source":"## Dataset Visualization","metadata":{}},{"cell_type":"markdown","source":"### Types","metadata":{}},{"cell_type":"code","source":"titanic_train.dtypes\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.Name.apply(lambda x: type(x).__name__).value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Every `object` are strings. If not, it means that they are `NaN` values.\nNo type issues for this dataset.","metadata":{}},{"cell_type":"markdown","source":"### Missing values","metadata":{}},{"cell_type":"code","source":"print(titanic_train.isnull().sum())\nprint(titanic_test.isnull().sum())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Duplicates","metadata":{}},{"cell_type":"code","source":"titanic_train.duplicated([\"PassengerId\"]).sum() + titanic_train.duplicated([\"Name\"]).sum()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summary statistics / Univariate analysis","metadata":{}},{"cell_type":"code","source":"print(titanic_train.Survived.value_counts())\nprint()\nprint(titanic_train.Pclass.value_counts())\nprint()\nprint(titanic_train.Embarked.value_counts())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(titanic_train.SibSp.value_counts())\nprint()\nprint(titanic_train.Parch.value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.loc[:, [\"SibSp\", \"Parch\", \"Age\", \"Fare\"]].describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate analysis","metadata":{}},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Age\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Sex\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Fare\", hue=\"Survived\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(data=titanic_train, x=\"Fare\", hue=\"Pclass\", kind=\"kde\")\nsns.displot(data=titanic_train, x=\"Fare\", hue=\"Survived\", kind=\"kde\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Pclass\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Embarked\", hue=\"Survived\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"SibSp\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Parch\", hue=\"Survived\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract features","metadata":{}},{"cell_type":"markdown","source":"### Family Names & Titles","metadata":{}},{"cell_type":"code","source":"titanic_train.Name","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[\"Last_name\"] = titanic_train.Name.apply(lambda x: str.split(x, \",\")[0])\ntitanic_test[\"Last_name\"] = titanic_test.Name.apply(lambda x: str.split(x, \",\")[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.Name.apply(lambda x: ((str.split(x, \",\")[1]).split(\".\")[0])).value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royal\",\n    \"Don\": \"Royal\",\n    \"Sir\": \"Royal\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\": \"Royal\",\n    \"Dona\": \"Royal\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\": \"Mr\",\n    \"Mrs\": \"Mrs\",\n    \"Miss\": \"Miss\",\n    \"Master\": \"Master\",\n    \"Lady\": \"Royal\",\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[\"Title\"] = titanic_train.Name.apply(\n    lambda x: Title_Dictionary[((str.split(x, \",\")[1]).split(\".\")[0]).strip()]\n)\n\ntitanic_test[\"Title\"] = titanic_test.Name.apply(\n    lambda x: Title_Dictionary[((str.split(x, \",\")[1]).split(\".\")[0]).strip()]\n)\n\ntitanic_train.Title.value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(titanic_train.groupby([\"Title\"]).Survived.mean(), 3)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `Title` is highly correlated to your chances to survive.","metadata":{}},{"cell_type":"markdown","source":"### Fare per person\n\n#### PeopleInTicket","metadata":{}},{"cell_type":"code","source":"titanic_train[\"PeopleInTicket\"] = titanic_train[\"Ticket\"].map(\n    combined_dataset[\"Ticket\"].value_counts()\n)\n\ntitanic_test[\"PeopleInTicket\"] = titanic_test[\"Ticket\"].map(\n    combined_dataset[\"Ticket\"].value_counts()\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### Fare Outliers / missing values","metadata":{}},{"cell_type":"code","source":"titanic_train[(titanic_train[\"Fare\"] == 0)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How can their fare be 0. All of them are middle aged males. All have embarked at one place. Most likely this is the Cabin crew. This can be considered as an outlier and must be solved.","metadata":{}},{"cell_type":"code","source":"round(\n    titanic_train.loc[:, [\"Pclass\", \"Embarked\", \"PeopleInTicket\", \"Fare\"]]\n    .groupby([\"Pclass\", \"Embarked\", \"PeopleInTicket\"])\n    .agg((\"count\", \"min\", \"mean\", \"max\")),\n    2,\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean ages from the train set\nmean_fares = titanic_train.groupby([\"Pclass\", \"Embarked\", \"PeopleInTicket\"])[\"Fare\"].mean()\n\n\n# Define a function to fill the missing values\ndef fill_fare(row):\n    if row[\"Fare\"] == 0 or pd.isna(row[\"Fare\"]):\n        return mean_fares[row[\"Pclass\"], row[\"Embarked\"], row[\"PeopleInTicket\"]]\n    else:\n        return row[\"Fare\"]\n\n\n# Use the function to fill the missing values in the train set\ntitanic_train[\"Fare\"] = titanic_train.apply(fill_fare, axis=1)\n\n# # Use the function to fill the missing values in the test set\ntitanic_test[\"Fare\"] = titanic_test.apply(fill_fare, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Family size","metadata":{}},{"cell_type":"code","source":"(titanic_train.Last_name).value_counts().value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[\"FamilySize\"] = titanic_train.SibSp + titanic_train.Parch + 1\ntitanic_test[\"FamilySize\"] = titanic_test.SibSp + titanic_test.Parch + 1\ntitanic_train[\"FamilySize\"].value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### PeopleInGroup","metadata":{}},{"cell_type":"code","source":"test = titanic_train.loc[\n    :, [\"Survived\", \"Pclass\", \"Fare\", \"FamilySize\", \"Embarked\", \"PeopleInTicket\"]\n]\ntest[\"PeopleInGroup\"] = test[[\"FamilySize\", \"PeopleInTicket\"]].max(axis=1)\n\n# test = test.loc[test.Embarked == \"S\"]\n# test = test.loc[test.Embarked == \"C\"]\n# test = test.loc[test.Embarked == \"Q\"]\n\ntest[\"FarePerPerson1\"] = test[\"Fare\"] / test[\"PeopleInTicket\"]\ntest[\"FarePerPerson2\"] = test[\"Fare\"] / test[\"FamilySize\"]\ntest[\"FarePerPerson3\"] = test[\"Fare\"] / test[\"PeopleInGroup\"]\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 5))\n\nsns.histplot(test, x=\"Fare\", hue=\"Pclass\", binwidth=4, ax=ax1)\nax1.set_xlim(0, 100)\n\nsns.histplot(test, x=\"FarePerPerson1\", hue=\"Pclass\", binwidth=4, ax=ax2)\nax2.set_xlim(0, 100)\n\nsns.histplot(test, x=\"FarePerPerson2\", hue=\"Pclass\", binwidth=4, ax=ax3)\nax3.set_xlim(0, 100)\n\nsns.histplot(test, x=\"FarePerPerson3\", hue=\"Pclass\", binwidth=4, ax=ax4)\nax4.set_xlim(0, 100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They are multiple possibilities to determine the new `Fare_per_person` from the `Fare` column.\n1. From the number of people on the same ticket `PeopleInTicket`\n2. From the number of people on the same ticket `FamilySize`\n3. From a mix of both columns `max(PeopleInTicket, FamilySize)`.\n\nFrom varying the `Embarked` parameter (because price of the tickets from the same Embarkation point should be closer), we can see that any of the methods is still more preferable that the others. However, values are more stacked with the second option (`PeopleInTicket`). People from the same family are not forced to buy it at the same time.\n","metadata":{}},{"cell_type":"code","source":"round(\n    test.loc[\n        :, [\"Pclass\", \"Embarked\", \"Fare\", \"FarePerPerson1\", \"FarePerPerson2\", \"FarePerPerson3\"]\n    ]\n    .groupby([\"Embarked\", \"Pclass\"])\n    .agg((\"count\", \"mean\", \"std\")),\n    2,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this final table, we see that using the `FarePerPerson1` option will reduce the most the variance. The option `FarePerPerson3` is still safe tho.","metadata":{}},{"cell_type":"code","source":"titanic_train[\"FarePerPerson\"] = titanic_train[\"Fare\"] / titanic_train[\"PeopleInTicket\"]\n\ntitanic_test[\"FarePerPerson\"] = titanic_test[\"Fare\"] / titanic_test[\"PeopleInTicket\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cabin deck letter","metadata":{}},{"cell_type":"code","source":"titanic_train[\"Cabin_deck\"] = titanic_train.Cabin.apply(lambda x: x[0] if type(x) == str else x)\ntitanic_test[\"Cabin_deck\"] = titanic_test.Cabin.apply(lambda x: x[0] if type(x) == str else x)\ntitanic_train[\"Cabin_deck\"].value_counts()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table_count = titanic_train.loc[:, [\"Ticket\", \"Cabin\", \"PeopleInTicket\"]].groupby(\"Ticket\").count()\ntable_count.loc[(table_count[\"Cabin\"] > 0) & (table_count[\"PeopleInTicket\"] > table_count[\"Cabin\"])]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[titanic_train.Ticket == \"PC 17757\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It will be too complicated to try to fill the blanks of the `Cabin` column. In addition, the information of the Cabin letter would have been useful to determine a potential position on the boat (which is even more complicated to implement). Thus, we will drop this column later and not use it. ","metadata":{}},{"cell_type":"markdown","source":"## Complete data","metadata":{}},{"cell_type":"markdown","source":"### Cabin\n\nNo reason to fill it if we will frop the column.","metadata":{}},{"cell_type":"markdown","source":"### Embarked","metadata":{}},{"cell_type":"code","source":"titanic_train[titanic_train.Embarked.isnull()]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[(titanic_train.Pclass == 1)].groupby(\"Embarked\").agg(\n    {\"FarePerPerson\": \"mean\", \"Fare\": \"mean\", \"PassengerId\": \"count\"}\n)\ntitanic_train.Embarked.fillna(\"C\", inplace=True)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Age","metadata":{}},{"cell_type":"markdown","source":"Filling the age is important to determine the autonomy of the person. The mean `Age` on the boat is 30. If we assign the same age to a child, we will probably not have the result.","metadata":{}},{"cell_type":"markdown","source":"Use transform when you want to maintain the same shape as the original DataFrame, but replace values based on group-based calculations. Use agg when you want to obtain a summary of each group.","metadata":{}},{"cell_type":"code","source":"titanic_train[\"Age\"].describe()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(\n    titanic_train.loc[:, [\"Pclass\", \"Embarked\", \"Age\", \"Title\", \"Sex\", \"SibSp\", \"Parch\"]]\n    .groupby([\"Embarked\", \"Pclass\", \"Title\"])\n    .agg((\"count\", \"min\", \"mean\", \"max\")),\n    2,\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(\n    titanic_train.loc[:, [\"Pclass\", \"Embarked\", \"Age\", \"Title\", \"Sex\"]]\n    .groupby([\"Embarked\", \"Pclass\", \"Title\", \"Sex\"])\n    .agg((\"count\", \"min\", \"mean\", \"max\")),\n    2,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(\n    titanic_train.loc[:, [\"Pclass\", \"Embarked\", \"Age\", \"Title\", \"Sex\"]]\n    .groupby([\"Pclass\", \"Title\", \"Sex\"])\n    .agg((\"count\", \"min\", \"mean\", \"max\")),\n    2,\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the mean ages from the train set\nmean_ages = titanic_train.groupby([\"Pclass\", \"Sex\", \"Title\"])[\"Age\"].mean()\n\n\n# Define a function to fill the missing values\ndef fill_age(row):\n    if pd.isnull(row[\"Age\"]):\n        return mean_ages[row[\"Pclass\"], row[\"Sex\"], row[\"Title\"]]\n    else:\n        return row[\"Age\"]\n\n\n# Use the function to fill the missing values in the train set\ntitanic_train[\"Age\"] = titanic_train.apply(fill_age, axis=1)\n\n# Use the function to fill the missing values in the test set\ntitanic_test[\"Age\"] = titanic_test.apply(fill_age, axis=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Select features","metadata":{}},{"cell_type":"markdown","source":"After having verified we have done as much work as we can to clean, fill missing values, to detect outliers and to create new features, it is high time to select features for the prediction model and to adjust the format of certains features (categorical feature, cyclic features, etc ...).","metadata":{}},{"cell_type":"code","source":"titanic_train = titanic_train.loc[\n    :,\n    [\n        \"Survived\",\n        \"Pclass\",\n        \"Sex\",\n        \"Age\",\n        \"SibSp\",\n        \"Parch\",\n        \"Embarked\",\n        \"Title\",\n        \"FamilySize\",\n        \"PeopleInTicket\",\n        \"FarePerPerson\",\n    ],\n]\n\ntitanic_test = titanic_test.loc[\n    :,\n    [\n        \"Pclass\",\n        \"Sex\",\n        \"Age\",\n        \"SibSp\",\n        \"Parch\",\n        \"Embarked\",\n        \"Title\",\n        \"FamilySize\",\n        \"PeopleInTicket\",\n        \"FarePerPerson\",\n    ],\n]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Binning","metadata":{}},{"cell_type":"markdown","source":"#### Age","metadata":{}},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Age\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the bin edges\nbins = [0, 16, 30, 40, 55, np.inf]\n\n# Define the labels for the bins\nlabels = [\"Young\", \"YoungAdult\", \"Adults\", \"Old\", \"VeryOld\"]\n\n# Create the new column\ntitanic_train[\"Age\"] = pd.cut(titanic_train[\"Age\"], bins=bins, labels=labels)\ntitanic_test[\"Age\"] = pd.cut(titanic_test[\"Age\"], bins=bins, labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### FarePerPerson","metadata":{}},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"FarePerPerson\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the bin edges\nbins = [0, 10, 20, 40, np.inf]\n\n# Define the labels for the bins\nlabels = [\"LowFare\", \"MediumFare\", \"HighFare\", \"VeryHighFare\"]\n\n# Create the new column\ntitanic_train[\"FarePerPerson\"] = pd.cut(titanic_train[\"FarePerPerson\"], bins=bins, labels=labels)\ntitanic_test[\"FarePerPerson\"] = pd.cut(titanic_test[\"FarePerPerson\"], bins=bins, labels=labels)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train[\"FarePerPerson\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"FarePerPerson\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### FamilySize / PeopleInTicket","metadata":{}},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=titanic_train, x=\"FamilySize\", hue=\"Survived\")\nplt.show()\n\nplt.figure()\nsns.countplot(data=titanic_train, x=\"PeopleInTicket\", hue=\"Survived\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have very close Barplot. This is due because most people having the same ticket are people from the same family.\nWe clearly see that we can bin those values in 3 categories. ","metadata":{}},{"cell_type":"code","source":"# Define the bin edges\nbins = [0, 1, 4, np.inf]\n\n# Define the labels for the bins\nlabels = [\"Solo\", \"SmallGroup\", \"LargeGroup\"]\n\n# Create the new column\ntitanic_train[\"FamilySize\"] = pd.cut(titanic_train[\"FamilySize\"], bins=bins, labels=labels)\ntitanic_test[\"FamilySize\"] = pd.cut(titanic_test[\"FamilySize\"], bins=bins, labels=labels)\n\ntitanic_train[\"PeopleInTicket\"] = pd.cut(titanic_train[\"PeopleInTicket\"], bins=bins, labels=labels)\ntitanic_test[\"PeopleInTicket\"] = pd.cut(titanic_test[\"PeopleInTicket\"], bins=bins, labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"PeopleInTicket\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### SibSp / ParCh","metadata":{}},{"cell_type":"code","source":"plt.figure()\nsns.countplot(data=titanic_train, x=\"SibSp\", hue=\"Survived\")\nplt.show()\n\nplt.figure()\nsns.countplot(data=titanic_train, x=\"Parch\", hue=\"Survived\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the bin edges\nbins = [-np.inf, 0, 2, np.inf]\n\n# Define the labels for the bins\nlabels = [\"NoSibSP\", \"FewSibSP\", \"LotSibSP\"]\n\n# Create the new column\ntitanic_train[\"SibSp\"] = pd.cut(titanic_train[\"SibSp\"], bins=bins, labels=labels)\ntitanic_test[\"SibSp\"] = pd.cut(titanic_test[\"SibSp\"], bins=bins, labels=labels)\n\n# Define the bin edges\nbins = [-np.inf, 0, 3, np.inf]\n\n# Define the labels for the bins\nlabels = [\"NoParch\", \"FewParch\", \"LotParch\"]\n\ntitanic_train[\"Parch\"] = pd.cut(titanic_train[\"Parch\"], bins=bins, labels=labels)\ntitanic_test[\"Parch\"] = pd.cut(titanic_test[\"Parch\"], bins=bins, labels=labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(titanic_train, x=\"Parch\", hue=\"Survived\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-hot encoding\n","metadata":{}},{"cell_type":"code","source":"titanic_train[\"Sex\"] = (titanic_train[\"Sex\"] == \"male\").astype(int)\ntitanic_test[\"Sex\"] = (titanic_test[\"Sex\"] == \"male\").astype(int)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Instantiate the OneHotEncoder\nenc = OneHotEncoder(sparse=False)\n\n# Suppose 'column1' and 'column2' are your categorical columns\n# Fit and transform the data, creating a new DataFrame\n\ncolumns_to_ohe = [\"Embarked\", \"Title\"]\ndf_encoded = pd.DataFrame(enc.fit_transform(titanic_train[columns_to_ohe]))\n\n# Give names to the new columns and concatenate with the original df\ndf_encoded.columns = enc.get_feature_names_out(columns_to_ohe)\ntitanic_train = pd.concat([titanic_train, df_encoded], axis=1).drop(columns_to_ohe, axis=1)\n\ndf_encoded = pd.DataFrame(enc.transform(titanic_test[columns_to_ohe]))\ndf_encoded.columns = enc.get_feature_names_out(columns_to_ohe)\ntitanic_test = pd.concat([titanic_test, df_encoded], axis=1).drop(columns_to_ohe, axis=1)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ordinal Encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n# Instantiate the OrdinalEncoder\nenc = OrdinalEncoder()\n\n# Columns to apply the encoding\ncolumns_to_encode = [\n    \"Pclass\",\n    \"Age\",\n    \"FamilySize\",\n    \"PeopleInTicket\",\n    \"SibSp\",\n    \"Parch\",\n    \"FarePerPerson\",\n]\n# columns_to_encode = [\"Pclass\"]\n\ndf_encoded = titanic_train[columns_to_encode].copy()\ndf_encoded = enc.fit_transform(df_encoded)\ndf_encoded = pd.DataFrame(df_encoded, columns=columns_to_encode)\ntitanic_train = pd.concat([titanic_train.drop(columns_to_encode, axis=1), df_encoded], axis=1)\n\ndf_encoded = titanic_test[columns_to_encode].copy()\ndf_encoded = enc.transform(df_encoded)\ndf_encoded = pd.DataFrame(df_encoded, columns=columns_to_encode)\ntitanic_test = pd.concat([titanic_test.drop(columns_to_encode, axis=1), df_encoded], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Standard scaling","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n\n# scaler = StandardScaler()\n\n# columns_to_scale = []\n# titanic_train[columns_to_scale] = scaler.fit_transform(titanic_train[columns_to_scale])\n# titanic_test[columns_to_scale] = scaler.transform(titanic_test[columns_to_scale])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(titanic_train.isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(titanic_test.isnull().sum())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train.dtypes\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Selection\n\n","metadata":{}},{"cell_type":"code","source":"correlation_matrix = titanic_train.corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n# separate your data into X and y\nX = titanic_train.drop(\"Survived\", axis=1)\ny = titanic_train[\"Survived\"]\n\n# apply SelectKBest class to extract the best features\nbestfeatures = SelectKBest(score_func=chi2, k=\"all\")\nfit = bestfeatures.fit(X, y)\n\n# create a DataFrame to visualize the scores\ndf_scores = pd.DataFrame(fit.scores_)\ndf_columns = pd.DataFrame(X.columns)\n\n# concatenate dataframes for better visualization and sort values\nfeature_scores = pd.concat([df_columns, df_scores], axis=1)\nfeature_scores.columns = [\"Feature\", \"Score\"]\nfeature_scores_sorted = feature_scores.sort_values(by=\"Score\", ascending=False)\n\nprint(feature_scores_sorted)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titanic_train = titanic_train.loc[\n    :,\n    [\n        \"Survived\",\n        \"Pclass\",\n        \"Sex\",\n        \"Age\",\n        \"SibSp\",\n        \"Parch\",\n        \"Embarked_C\",\n        \"Embarked_Q\",\n        \"Embarked_S\",\n        \"Title_Master\",\n        \"Title_Miss\",\n        \"Title_Mr\",\n        \"Title_Mrs\",\n        \"Title_Officer\",\n        \"Title_Royal\",\n        \"FamilySize\",\n        \"PeopleInTicket\",\n        \"FarePerPerson\",\n    ],\n]\n\ntitanic_test = titanic_test.loc[\n    :,\n    [\n        \"Pclass\",\n        \"Sex\",\n        \"Age\",\n        \"SibSp\",\n        \"Parch\",\n        \"Embarked_C\",\n        \"Embarked_Q\",\n        \"Embarked_S\",\n        \"Title_Master\",\n        \"Title_Miss\",\n        \"Title_Mr\",\n        \"Title_Mrs\",\n        \"Title_Officer\",\n        \"Title_Royal\",\n        \"FamilySize\",\n        \"PeopleInTicket\",\n        \"FarePerPerson\",\n    ],\n]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine learning","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\nclassifiers = {\n    \"LogisticRegression\": LogisticRegression(),\n    \"SVC\": SVC(),\n    \"RandomForestClassifier\": RandomForestClassifier(),\n    \"KNeighborsClassifier\": KNeighborsClassifier(),\n    # \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n    \"XGBClassifier\": XGBClassifier(eval_metric=\"logloss\"),\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = {\n#     \"LogisticRegression\": {\n#         \"C\": [0.1, 1.0, 10.0],\n#         \"solver\": [\"lbfgs\", \"liblinear\"],\n#         \"max_iter\": [5000],\n#     },\n#     \"SVC\": {\"C\": [0.1, 1.0, 10.0], \"kernel\": [\"linear\", \"rbf\"]},\n#     \"RandomForestClassifier\": {\"n_estimators\": [10, 100, 1000], \"max_depth\": [None, 10, 20]},\n#     \"KNeighborsClassifier\": {\n#         \"n_neighbors\": range(1, 21),\n#         \"p\": [1, 2],\n#     },\n#     \"DecisionTreeClassifier\": {\n#         \"max_depth\": [None, 10, 20, 30, 40],\n#         \"min_samples_split\": [2, 10, 20],\n#     },\n#     \"GradientBoostingClassifier\": {\n#         \"learning_rate\": [0.01, 0.1, 1.0],\n#         \"n_estimators\": [100, 500, 1000],\n#     },\n#     \"XGBClassifier\": {\"learning_rate\": [0.01, 0.1, 1.0], \"n_estimators\": [100, 500, 1000]},\n# }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"LogisticRegression\": {\n        \"C\": [0.1],\n        \"solver\": [\"lbfgs\", \"liblinear\"],\n        \"max_iter\": [5000],\n    },\n    \"SVC\": {\n        \"C\": [0.4],\n        \"kernel\": [\"rbf\"],\n        \"gamma\": [\"scale\"],\n    },\n    \"RandomForestClassifier\": {\n        \"n_estimators\": [1000],\n        \"max_depth\": [5],\n        \"max_features\": [\"sqrt\"],\n    },\n    \"KNeighborsClassifier\": {\n        \"n_neighbors\": range(1, 41),\n        \"p\": [2],\n    },\n    \"GradientBoostingClassifier\": {\n        \"learning_rate\": [0.01],\n        \"n_estimators\": [350],\n        \"max_depth\": [5],\n        \"subsample\": [0.8],\n    },\n    \"XGBClassifier\": {\n        \"learning_rate\": [0.007],\n        \"n_estimators\": [300],\n        \"max_depth\": [7],\n        \"subsample\": [0.5],\n    },\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = titanic_train.drop(\"Survived\", axis=1)\ny_train = titanic_train[\"Survived\"]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, cross_val_score\n\nmodel_score = {}\nfolds = 10\n\nfor classifier_name in classifiers.keys():\n    clf = classifiers[classifier_name]\n    param_grid = params[classifier_name]\n\n    # Perform grid search with cross-validation\n    grid_search = GridSearchCV(clf, param_grid, cv=folds)  # 5-fold cross-validation\n    grid_search.fit(X_train, y_train)\n\n    # Calculate additional scores\n    f1_score = cross_val_score(\n        grid_search.best_estimator_, X_train, y_train, cv=folds, scoring=\"f1\"\n    ).mean()\n    auc_score = cross_val_score(\n        grid_search.best_estimator_, X_train, y_train, cv=folds, scoring=\"roc_auc\"\n    ).mean()\n\n    model_score[classifier_name] = {\n        \"Best Score\": grid_search.best_score_,\n        \"F1 Score\": f1_score,\n        \"AUC\": auc_score,\n    }\n    print(classifier_name)\n    print(f\"Best parameters : {grid_search.best_params_}\")\n    print(f\"Best score : {grid_search.best_score_}\")\n    print(f\"F1 score : {f1_score}\")\n    print(f\"AUC : {auc_score}\")\n    print()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert nested dictionary into flat dictionary\nflat_data = []\nfor model, scores in model_score.items():\n    flat_scores = {\"Model\": model, **scores}\n    flat_data.append(flat_scores)\n\n# Create dataframe from flat dictionary\ndf_model_score = pd.DataFrame(flat_data)\n\n# Sort by Score\ndf_model_score.sort_values(by=\"Best Score\", ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"# Suppose your best model was logistic regression\nbest_model = grid_search.best_estimator_\nX_test = titanic_test\n\n# Make predictions\npredictions = best_model.predict(X_test)\n\n# Assuming that the test DataFrame is ordered correctly\ntitanic_test[\"PassengerId\"] = range(892, 892 + len(titanic_test))\n\n# Create a DataFrame with the passenger ids and the corresponding predictions\nsubmission = pd.DataFrame({\"PassengerId\": titanic_test[\"PassengerId\"], \"Survived\": predictions})\n\n# Save the DataFrame to a CSV file\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle competitions submit -f submission.csv -m \"\"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle competitions submissions titanic\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_leaderboard = pd.read_csv(\"leaderboard.csv\")\ndf_leaderboard.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_myscore = pd.DataFrame({\"ScoreId\": [0, 1], \"Score\": [0.75358, 0.7703]})\ndf_myscore.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nsns.histplot(df_leaderboard, x=\"Score\")\nplt.xlim([0.7, 0.85])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.patches as mpatches\n\nplt.figure(figsize=(10, 5))\nplt.hist(df_leaderboard[\"Score\"], bins=300, alpha=0.5, label=\"Leaderboard Scores\")\nfor index, row in df_myscore.iterrows():\n    plt.axvline(row[\"Score\"], color=\"r\", linestyle=\"dashed\", linewidth=2)\n\n\nred_patch = mpatches.Patch(color=\"red\", label=\"Your Scores\")\nplt.legend(handles=[red_patch])\nplt.xlim([0.7, 0.85])\nplt.xlabel(\"Score\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.title(\"Leaderboard Scores and Your Score\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}